#!/usr/bin/env python3
"""
Script para obtener los pr√≥ximos 10 PDFs reales usando el m√©todo PLoS ONE funcionar.
"""
import sys
import os
import pandas as pd

# Agregar directorio scrapers al path
sys.path.append('scrapers')

from journal_pubmed_scraper import JournalPubMedScraper
from github_scraper import GitHubCSVScraper

def main():
    """Obtiene los pr√≥ximos 10 PDFs reales."""
    print("üéØ OBTENIENDO PR√ìXIMOS 10 PDFs REALES")
    print("=" * 50)
    
    try:
        # Paso 1: Obtener datos del CSV
        print("\nüìä Paso 1: Obteniendo datos del CSV de GitHub...")
        github_scraper = GitHubCSVScraper("https://raw.githubusercontent.com/jgalazka/SB_publications/main/SB_publication_PMC.csv")
        articles_df = github_scraper.scrape()
        
        print(f"‚úÖ {len(articles_df)} art√≠culos encontrados en total")
        
        # Paso 2: Seleccionar primeros 10 art√≠culos PLoS ONE
        print("\nüîç Paso 2: Seleccionando art√≠culos PLoS ONE...")
        
        # Buscar art√≠culos que sean de PLoS ONE (t√≠picamente contienen 'pone' en URL)
        plos_articles = []
        for _, row in articles_df.iterrows():
            url = row['Link']
            title = row['Title']
            
            # Detectar si es PLoS ONE
            if 'pone' in url.lower() or 'plos' in url.lower():
                plos_articles.append({'Title': title, 'Link': url})
                if len(plos_articles) >= 10:
                    break
        
        print(f"üìã Encontrados {len(plos_articles)} art√≠culos PLoS ONE")
        
        if not plos_articles:
            print("‚ö†Ô∏è No se encontraron art√≠culos PLoS ONE en los primeros")
            print("üîÑ Usando primeros 10 art√≠culos disponibles...")
            test_articles = articles_df.head(10).to_dict('records')
        else:
            test_articles = plos_articles
        
        # Mostrar qu√© art√≠culos vamos a procesar
        print(f"\nüìã ART√çCULOS A PROCESAR ({len(test_articles)}):")
        for i, article in enumerate(test_articles):
            title = article['Title']
            url = article['Link']
            journal = 'PLoS ONE' if 'pone' in url.lower() else 'Unknown'
            print(f"   {i+1:2d}. [{journal}] {title[:50]}...")
            print(f"       URL: {url}")
        
        # Paso 3: Crear scraper de journals
        print(f"\nüîß Paso 3: Configurando scraper de journals...")
        scraper = JournalPubMedScraper(download_dir="./downloads_functional", delay=1.0)
        
        # Convertir a DataFrame para el scraper
        test_df = pd.DataFrame(test_articles)
        
        # Paso 4: Descargar PDFs reales
        print(f"\nüöÄ Paso 4: Descargando PDFs usando m√©todos espec√≠ficos de journals...")
        files = scraper.download_multiple_real(test_df, max_articles=len(test_df))
        
        # Paso 5: An√°lisis de resultados
        print(f"\nüìä RESULTADOS FINALES:")
        print("=" * 40)
        
        if files:
            print(f"‚úÖ ¬°√âXITO! {len(files)} PDFs reales descargados:")
            print()
            
            total_size = 0
            valid_count = 0
            
            for filepath in files:
                size = os.path.getsize(filepath)
                total_size += size
                filename = os.path.basename(filepath)
                
                # Verificar si es PDF v√°lido
                try:
                    with open(filepath, 'rb') as f:
                        header = f.read(10)
                        is_valid = header.startswith(b'%PDF')
                        
                    if is_valid:
                        valid_count += 1
                        status = "‚úÖ V√ÅLIDO"
                    else:
                        status = "‚ùå INV√ÅLIDO"
                        
                    print(f"   üìÑ {filename}")
                    print(f"      {status} - {size:,} bytes ({size/1024/1024:.2f} MB)")
                    
                except Exception as e:
                    print(f"   üìÑ {filename}")
                    print(f"      ‚ùå ERROR: {e}")
            
            print(f"\nüìà RESUMEN:")
            print(f"   ‚Ä¢ PDFs totales descargados: {len(files)}")
            print(f"   ‚Ä¢ PDFs v√°lidos: {valid_count}")
            print(f"   ‚Ä¢ Tasa de √©xito: {len(files)}/{len(test_articles)} ({len(files)/len(test_articles)*100:.1f}%)")
            print(f"   ‚Ä¢ Tama√±o total: {total_size:,} bytes ({total_size/1024/1024:.1f} MB)")
            
            if len(files) > 0:
                avg_size = total_size / len(files)
                print(f"   ‚Ä¢ Tama√±o promedio: {avg_size:,} bytes ({avg_size/1024/1024:.2f} MB)")
                
                if avg_size > 1000000:  # >1MB promedio
                    print(f"   üéØ ¬°Los PDFs son REALES! (Promedio >1MB)")
                elif avg_size > 500000:  # >500KB promedio
                    print(f"   ‚úÖ Los PDFs parecen v√°lidos (Promedio >500KB)")
                else:
                    print(f"   ‚ö†Ô∏è PDFs a√∫n muy peque√±os (Promedio <500KB)")
            
            print(f"\nüíæ Archivos guardados en: ./downloads_functional/")
            
            # Mostrar archivos creados
            if os.path.exists("./downloads_functional"):
                print(f"\nüìÅ ARCHIVOS EN DOWNLOADS_FUNCTIONAL:")
                for f in os.listdir("./downloads_functional"):
                    if f.endswith('.pdf'):
                        size = os.path.getsize(os.path.join("./downloads_functional", f))
                        print(f"   üìÑ {f} ({size:,} bytes)")
        
        else:
            print(f"‚ùå No se obtuvieron PDFs v√°lidos")
            print(f"üí° Esto puede indicar:")
            print(f"   ‚Ä¢ Los journals bloquearon autom√°ticamente las descargas")
            print(f"   ‚Ä¢ Se necesita configuraci√≥n adicional para Chrome")
            print(f"   ‚Ä¢ Los art√≠culos no son de PLoS ONE")
        
        print(f"\nüéâ PROCESO COMPLETADO")
        
    except Exception as e:
        print(f"‚ùå Error en proceso: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
